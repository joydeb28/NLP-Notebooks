{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport json\nimport os\nfrom sklearn.metrics import roc_curve\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.model_selection import train_test_split\nimport torch\nimport torch.nn as nn\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import classification_report\nimport transformers\nfrom transformers import AutoModel, BertTokenizerFast\n\n# specify GPU\ndevice = torch.device(\"cuda\")","execution_count":2,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"class LoadingData():\n            \n    def __init__(self):\n        train_file_path = os.path.join(\"..\",\"input\",\"nlp-benchmarking-data-for-intent-and-entity\",\"benchmarking_data\",\"Train\")\n        validation_file_path = os.path.join(\"..\",\"input\",\"nlp-benchmarking-data-for-intent-and-entity\",\"benchmarking_data\",\"Validate\")\n        category_id = 0\n        self.cat_to_intent = {}\n        self.intent_to_cat = {}\n        \n        for dirname, _, filenames in os.walk(train_file_path):\n            for filename in filenames:\n                file_path = os.path.join(dirname, filename)\n                intent_id = filename.replace(\".json\",\"\")\n                self.cat_to_intent[category_id] = intent_id\n                self.intent_to_cat[intent_id] = category_id\n                category_id+=1\n        print(self.cat_to_intent)\n        print(self.intent_to_cat)\n        '''Training data'''\n        training_data = list() \n        for dirname, _, filenames in os.walk(train_file_path):\n            for filename in filenames:\n                file_path = os.path.join(dirname, filename)\n                intent_id = filename.replace(\".json\",\"\")\n                training_data+=self.make_data_for_intent_from_json(file_path,intent_id,self.intent_to_cat[intent_id])\n        self.train_data_frame = pd.DataFrame(training_data, columns =['query', 'intent','category'])   \n        \n        self.train_data_frame = self.train_data_frame.sample(frac = 1)\n\n\n        \n        '''Validation data'''\n        validation_data = list()    \n        for dirname, _, filenames in os.walk(validation_file_path):\n            for filename in filenames:\n                file_path = os.path.join(dirname, filename)\n                intent_id = filename.replace(\".json\",\"\")\n                validation_data +=self.make_data_for_intent_from_json(file_path,intent_id,self.intent_to_cat[intent_id])                \n        self.validation_data_frame = pd.DataFrame(validation_data, columns =['query', 'intent','category'])\n\n        self.validation_data_frame = self.validation_data_frame.sample(frac = 1)\n        \n        \n    def make_data_for_intent_from_json(self,json_file,intent_id,cat):\n        json_d = json.load(open(json_file))         \n        \n        json_dict = json_d[intent_id]\n\n        sent_list = list()\n        for i in json_dict:\n            each_list = i['data']\n            sent =\"\"\n            for i in each_list:\n                sent = sent + i['text']+ \" \"\n            sent =sent[:-1]\n            for i in range(3):\n                sent = sent.replace(\"  \",\" \")\n            sent_list.append((sent,intent_id,cat))\n        return sent_list","execution_count":3,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"load_data_obj = LoadingData()","execution_count":4,"outputs":[{"output_type":"stream","text":"{0: 'PlayMusic', 1: 'AddToPlaylist', 2: 'BookRestaurant', 3: 'RateBook', 4: 'SearchScreeningEvent', 5: 'SearchCreativeWork', 6: 'GetWeather'}\n{'PlayMusic': 0, 'AddToPlaylist': 1, 'BookRestaurant': 2, 'RateBook': 3, 'SearchScreeningEvent': 4, 'SearchCreativeWork': 5, 'GetWeather': 6}\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"load_data_obj.train_data_frame.head(20)","execution_count":5,"outputs":[{"output_type":"execute_result","execution_count":5,"data":{"text/plain":"                                                   query  \\\n8897   I need to know what theatre is playing A Happy...   \n2939   Add Marianne Faithfull to june's Hillary Clint...   \n10512          Look for the Editor & Publisher TV series   \n4110   Can you book a table for a party of 6 close to...   \n10287                Show me a novel by Onnaam Muhurtham   \n10191                  Find a show called Chompa Toung .   \n1308                           Play 1958 music on Iheart   \n4190   book me a diner close-by Benin that serves str...   \n9265      is Tarzan of the Apes playing at Cobb Theatres   \n7047                Give zero stars to Book of Artifacts   \n4043   gwen carter and I want a reservation in the Do...   \n1483    Play me a song by Hank Thompson from Moa Anbessa   \n2994                       add this tune to my Rock This   \n10627     show creativity of the game Everything at Once   \n5324   Book me a table at a romanian brasserie in Rix...   \n13351                Will there be a blizzard in Egypt ?   \n1432                     play Sunshine Reggae on youtube   \n4932             Need a table for rita, antoinette and I   \n1035                          play my De Camino playlist   \n7953                     Find the movie schedules for me   \n\n                     intent  category  \n8897   SearchScreeningEvent         4  \n2939          AddToPlaylist         1  \n10512    SearchCreativeWork         5  \n4110         BookRestaurant         2  \n10287    SearchCreativeWork         5  \n10191    SearchCreativeWork         5  \n1308              PlayMusic         0  \n4190         BookRestaurant         2  \n9265   SearchScreeningEvent         4  \n7047               RateBook         3  \n4043         BookRestaurant         2  \n1483              PlayMusic         0  \n2994          AddToPlaylist         1  \n10627    SearchCreativeWork         5  \n5324         BookRestaurant         2  \n13351            GetWeather         6  \n1432              PlayMusic         0  \n4932         BookRestaurant         2  \n1035              PlayMusic         0  \n7953   SearchScreeningEvent         4  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>query</th>\n      <th>intent</th>\n      <th>category</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>8897</th>\n      <td>I need to know what theatre is playing A Happy...</td>\n      <td>SearchScreeningEvent</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>2939</th>\n      <td>Add Marianne Faithfull to june's Hillary Clint...</td>\n      <td>AddToPlaylist</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>10512</th>\n      <td>Look for the Editor &amp; Publisher TV series</td>\n      <td>SearchCreativeWork</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>4110</th>\n      <td>Can you book a table for a party of 6 close to...</td>\n      <td>BookRestaurant</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>10287</th>\n      <td>Show me a novel by Onnaam Muhurtham</td>\n      <td>SearchCreativeWork</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>10191</th>\n      <td>Find a show called Chompa Toung .</td>\n      <td>SearchCreativeWork</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>1308</th>\n      <td>Play 1958 music on Iheart</td>\n      <td>PlayMusic</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4190</th>\n      <td>book me a diner close-by Benin that serves str...</td>\n      <td>BookRestaurant</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>9265</th>\n      <td>is Tarzan of the Apes playing at Cobb Theatres</td>\n      <td>SearchScreeningEvent</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>7047</th>\n      <td>Give zero stars to Book of Artifacts</td>\n      <td>RateBook</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>4043</th>\n      <td>gwen carter and I want a reservation in the Do...</td>\n      <td>BookRestaurant</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>1483</th>\n      <td>Play me a song by Hank Thompson from Moa Anbessa</td>\n      <td>PlayMusic</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2994</th>\n      <td>add this tune to my Rock This</td>\n      <td>AddToPlaylist</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>10627</th>\n      <td>show creativity of the game Everything at Once</td>\n      <td>SearchCreativeWork</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>5324</th>\n      <td>Book me a table at a romanian brasserie in Rix...</td>\n      <td>BookRestaurant</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>13351</th>\n      <td>Will there be a blizzard in Egypt ?</td>\n      <td>GetWeather</td>\n      <td>6</td>\n    </tr>\n    <tr>\n      <th>1432</th>\n      <td>play Sunshine Reggae on youtube</td>\n      <td>PlayMusic</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4932</th>\n      <td>Need a table for rita, antoinette and I</td>\n      <td>BookRestaurant</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>1035</th>\n      <td>play my De Camino playlist</td>\n      <td>PlayMusic</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>7953</th>\n      <td>Find the movie schedules for me</td>\n      <td>SearchScreeningEvent</td>\n      <td>4</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_text, temp_text, train_labels, temp_labels = train_test_split(load_data_obj.train_data_frame['query'], load_data_obj.train_data_frame['category'], \n                                                                    random_state=2018, \n                                                                    test_size=0.3, \n                                                                    stratify=load_data_obj.train_data_frame['category'])\n\n# we will use temp_text and temp_labels to create validation and test set\nval_text, test_text, val_labels, test_labels = train_test_split(temp_text, temp_labels, \n                                                                random_state=2018, \n                                                                test_size=0.5, \n                                                                stratify=temp_labels)","execution_count":6,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# import BERT-base pretrained model\nbert = AutoModel.from_pretrained('bert-base-uncased')\n\n# Load the BERT tokenizer\ntokenizer = BertTokenizerFast.from_pretrained('bert-base-uncased')","execution_count":7,"outputs":[{"output_type":"display_data","data":{"text/plain":"HBox(children=(FloatProgress(value=0.0, description='Downloading', max=433.0, style=ProgressStyle(description_…","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b2bdca4605cc408c90310cd8f4947944"}},"metadata":{}},{"output_type":"stream","text":"\n","name":"stdout"},{"output_type":"display_data","data":{"text/plain":"HBox(children=(FloatProgress(value=0.0, description='Downloading', max=440473133.0, style=ProgressStyle(descri…","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"942719437e3c4766bb4171379c575c82"}},"metadata":{}},{"output_type":"stream","text":"\n","name":"stdout"},{"output_type":"display_data","data":{"text/plain":"HBox(children=(FloatProgress(value=0.0, description='Downloading', max=231508.0, style=ProgressStyle(descripti…","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ac480f407f8e42f8a63b722e133a197d"}},"metadata":{}},{"output_type":"stream","text":"\n","name":"stdout"},{"output_type":"display_data","data":{"text/plain":"HBox(children=(FloatProgress(value=0.0, description='Downloading', max=466062.0, style=ProgressStyle(descripti…","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8173ace9a894414cba28a62acd5cceb4"}},"metadata":{}},{"output_type":"stream","text":"\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"seq_len = [len(i.split()) for i in train_text]\n\npd.Series(seq_len).hist(bins = 30)","execution_count":8,"outputs":[{"output_type":"execute_result","execution_count":8,"data":{"text/plain":"<matplotlib.axes._subplots.AxesSubplot at 0x7f934788c090>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<Figure size 432x288 with 1 Axes>","image/png":"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\n"},"metadata":{"needs_background":"light"}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"max_seq_len = max(seq_len)\nprint(max_seq_len)","execution_count":9,"outputs":[{"output_type":"stream","text":"35\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"# tokenize and encode sequences in the training set\ntokens_train = tokenizer.batch_encode_plus(\n    train_text.tolist(),\n    max_length = max_seq_len,\n    pad_to_max_length=True,\n    truncation=True,\n    return_token_type_ids=False\n)\n\n# tokenize and encode sequences in the validation set\ntokens_val = tokenizer.batch_encode_plus(\n    val_text.tolist(),\n    max_length = max_seq_len,\n    pad_to_max_length=True,\n    truncation=True,\n    return_token_type_ids=False\n)\n\n# tokenize and encode sequences in the test set\ntokens_test = tokenizer.batch_encode_plus(\n    test_text.tolist(),\n    max_length = max_seq_len,\n    pad_to_max_length=True,\n    truncation=True,\n    return_token_type_ids=False\n)","execution_count":10,"outputs":[{"output_type":"stream","text":"/opt/conda/lib/python3.7/site-packages/transformers/tokenization_utils_base.py:1944: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n  FutureWarning,\n","name":"stderr"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"# for train set\ntrain_seq = torch.tensor(tokens_train['input_ids'])\ntrain_mask = torch.tensor(tokens_train['attention_mask'])\ntrain_y = torch.tensor(train_labels.tolist())\n\n# for validation set\nval_seq = torch.tensor(tokens_val['input_ids'])\nval_mask = torch.tensor(tokens_val['attention_mask'])\nval_y = torch.tensor(val_labels.tolist())\n\n# for test set\ntest_seq = torch.tensor(tokens_test['input_ids'])\ntest_mask = torch.tensor(tokens_test['attention_mask'])\ntest_y = torch.tensor(test_labels.tolist())","execution_count":11,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n\n#define a batch size\nbatch_size = 32\n\n# wrap tensors\ntrain_data = TensorDataset(train_seq, train_mask, train_y)\n\n# sampler for sampling the data during training\ntrain_sampler = RandomSampler(train_data)\n\n# dataLoader for train set\ntrain_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n\n# wrap tensors\nval_data = TensorDataset(val_seq, val_mask, val_y)\n\n# sampler for sampling the data during training\nval_sampler = SequentialSampler(val_data)\n\n# dataLoader for validation set\nval_dataloader = DataLoader(val_data, sampler = val_sampler, batch_size=batch_size)","execution_count":12,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# freeze all the parameters\nfor param in bert.parameters():\n    param.requires_grad = False","execution_count":13,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class BERT_Arch(nn.Module):\n\n    def __init__(self, bert):\n      \n      super(BERT_Arch, self).__init__()\n\n      self.bert = bert \n      \n      # dropout layer\n      self.dropout = nn.Dropout(0.1)\n      \n      # relu activation function\n      self.relu =  nn.ReLU()\n\n      # dense layer 1\n      self.fc1 = nn.Linear(768,512)\n      \n      # dense layer 2 (Output layer)\n      self.fc2 = nn.Linear(512,7)\n\n      #softmax activation function\n      self.softmax = nn.LogSoftmax(dim=1)\n\n    #define the forward pass\n    def forward(self, sent_id, mask):\n\n      #pass the inputs to the model  \n      _, cls_hs = self.bert(sent_id, attention_mask=mask)\n      \n      x = self.fc1(cls_hs)\n\n      x = self.relu(x)\n\n      x = self.dropout(x)\n\n      # output layer\n      x = self.fc2(x)\n      \n      # apply softmax activation\n      x = self.softmax(x)\n\n      return x","execution_count":14,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# pass the pre-trained BERT to our define architecture\nmodel = BERT_Arch(bert)\n\n# push the model to GPU\nmodel = model.to(device)","execution_count":15,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# optimizer from hugging face transformers\nfrom transformers import AdamW\n\n# define the optimizer\noptimizer = AdamW(model.parameters(), lr = 1e-3)","execution_count":16,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.utils.class_weight import compute_class_weight\n\n#compute the class weights\nclass_wts = compute_class_weight('balanced', np.unique(train_labels), train_labels)\n\nprint(class_wts)","execution_count":17,"outputs":[{"output_type":"stream","text":"[0.9844898  1.01419111 0.99803455 1.00678284 1.00531416 1.0075188\n 0.9844898 ]\n","name":"stdout"},{"output_type":"stream","text":"/opt/conda/lib/python3.7/site-packages/sklearn/utils/validation.py:70: FutureWarning: Pass classes=[0 1 2 3 4 5 6], y=6623     3\n7940     4\n3130     1\n8301     4\n9538     4\n        ..\n11786    6\n8366     4\n1098     0\n7145     3\n8771     4\nName: category, Length: 9648, dtype: int64 as keyword args. From version 0.25 passing these as positional arguments will result in an error\n  FutureWarning)\n","name":"stderr"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"# convert class weights to tensor\nweights= torch.tensor(class_wts,dtype=torch.float)\nweights = weights.to(device)\n\n# loss function\ncross_entropy  = nn.NLLLoss(weight=weights) \n\n# number of training epochs\nepochs = 10","execution_count":18,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# function to train the model\ndef train():\n  \n  model.train()\n\n  total_loss, total_accuracy = 0, 0\n  \n  # empty list to save model predictions\n  total_preds=[]\n  \n  # iterate over batches\n  for step,batch in enumerate(train_dataloader):\n    \n    # progress update after every 50 batches.\n    if step % 50 == 0 and not step == 0:\n      print('  Batch {:>5,}  of  {:>5,}.'.format(step, len(train_dataloader)))\n\n    # push the batch to gpu\n    batch = [r.to(device) for r in batch]\n \n    sent_id, mask, labels = batch\n\n    # clear previously calculated gradients \n    model.zero_grad()        \n\n    # get model predictions for the current batch\n    preds = model(sent_id, mask)\n\n    # compute the loss between actual and predicted values\n    loss = cross_entropy(preds, labels)\n\n    # add on to the total loss\n    total_loss = total_loss + loss.item()\n\n    # backward pass to calculate the gradients\n    loss.backward()\n\n    # clip the the gradients to 1.0. It helps in preventing the exploding gradient problem\n    torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n\n    # update parameters\n    optimizer.step()\n\n    # model predictions are stored on GPU. So, push it to CPU\n    preds=preds.detach().cpu().numpy()\n\n    # append the model predictions\n    total_preds.append(preds)\n\n  # compute the training loss of the epoch\n  avg_loss = total_loss / len(train_dataloader)\n  \n  # predictions are in the form of (no. of batches, size of batch, no. of classes).\n  # reshape the predictions in form of (number of samples, no. of classes)\n  total_preds  = np.concatenate(total_preds, axis=0)\n\n  #returns the loss and predictions\n  return avg_loss, total_preds","execution_count":19,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# function for evaluating the model\ndef evaluate():\n  \n  print(\"\\nEvaluating...\")\n  \n  # deactivate dropout layers\n  model.eval()\n\n  total_loss, total_accuracy = 0, 0\n  \n  # empty list to save the model predictions\n  total_preds = []\n\n  # iterate over batches\n  for step,batch in enumerate(val_dataloader):\n    \n    # Progress update every 50 batches.\n    if step % 50 == 0 and not step == 0:\n      \n      # Calculate elapsed time in minutes.\n      #elapsed = format_time(time.time() - t0)\n            \n      # Report progress.\n      print('  Batch {:>5,}  of  {:>5,}.'.format(step, len(val_dataloader)))\n\n    # push the batch to gpu\n    batch = [t.to(device) for t in batch]\n\n    sent_id, mask, labels = batch\n\n    # deactivate autograd\n    with torch.no_grad():\n      \n      # model predictions\n      preds = model(sent_id, mask)\n\n      # compute the validation loss between actual and predicted values\n      loss = cross_entropy(preds,labels)\n\n      total_loss = total_loss + loss.item()\n\n      preds = preds.detach().cpu().numpy()\n\n      total_preds.append(preds)\n\n  # compute the validation loss of the epoch\n  avg_loss = total_loss / len(val_dataloader) \n\n  # reshape the predictions in form of (number of samples, no. of classes)\n  total_preds  = np.concatenate(total_preds, axis=0)\n\n  return avg_loss, total_preds","execution_count":20,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# set initial loss to infinite\nbest_valid_loss = float('inf')\n\n# empty lists to store training and validation loss of each epoch\ntrain_losses=[]\nvalid_losses=[]\n\n#for each epoch\nfor epoch in range(epochs):\n     \n    print('\\n Epoch {:} / {:}'.format(epoch + 1, epochs))\n    \n    #train model\n    train_loss, _ = train()\n    \n    #evaluate model\n    valid_loss, _ = evaluate()\n    \n    #save the best model\n    if valid_loss < best_valid_loss:\n        best_valid_loss = valid_loss\n        torch.save(model.state_dict(), 'saved_weights.pt')\n    \n    # append training and validation loss\n    train_losses.append(train_loss)\n    valid_losses.append(valid_loss)\n    \n    print(f'\\nTraining Loss: {train_loss:.3f}')\n    print(f'Validation Loss: {valid_loss:.3f}')","execution_count":21,"outputs":[{"output_type":"stream","text":"\n Epoch 1 / 10\n  Batch    50  of    302.\n  Batch   100  of    302.\n  Batch   150  of    302.\n  Batch   200  of    302.\n  Batch   250  of    302.\n  Batch   300  of    302.\n\nEvaluating...\n  Batch    50  of     65.\n\nTraining Loss: 1.364\nValidation Loss: 0.743\n\n Epoch 2 / 10\n  Batch    50  of    302.\n  Batch   100  of    302.\n  Batch   150  of    302.\n  Batch   200  of    302.\n  Batch   250  of    302.\n  Batch   300  of    302.\n\nEvaluating...\n  Batch    50  of     65.\n\nTraining Loss: 0.665\nValidation Loss: 0.524\n\n Epoch 3 / 10\n  Batch    50  of    302.\n  Batch   100  of    302.\n  Batch   150  of    302.\n  Batch   200  of    302.\n  Batch   250  of    302.\n  Batch   300  of    302.\n\nEvaluating...\n  Batch    50  of     65.\n\nTraining Loss: 0.495\nValidation Loss: 0.354\n\n Epoch 4 / 10\n  Batch    50  of    302.\n  Batch   100  of    302.\n  Batch   150  of    302.\n  Batch   200  of    302.\n  Batch   250  of    302.\n  Batch   300  of    302.\n\nEvaluating...\n  Batch    50  of     65.\n\nTraining Loss: 0.413\nValidation Loss: 0.449\n\n Epoch 5 / 10\n  Batch    50  of    302.\n  Batch   100  of    302.\n  Batch   150  of    302.\n  Batch   200  of    302.\n  Batch   250  of    302.\n  Batch   300  of    302.\n\nEvaluating...\n  Batch    50  of     65.\n\nTraining Loss: 0.399\nValidation Loss: 0.272\n\n Epoch 6 / 10\n  Batch    50  of    302.\n  Batch   100  of    302.\n  Batch   150  of    302.\n  Batch   200  of    302.\n  Batch   250  of    302.\n  Batch   300  of    302.\n\nEvaluating...\n  Batch    50  of     65.\n\nTraining Loss: 0.372\nValidation Loss: 0.364\n\n Epoch 7 / 10\n  Batch    50  of    302.\n  Batch   100  of    302.\n  Batch   150  of    302.\n  Batch   200  of    302.\n  Batch   250  of    302.\n  Batch   300  of    302.\n\nEvaluating...\n  Batch    50  of     65.\n\nTraining Loss: 0.346\nValidation Loss: 0.255\n\n Epoch 8 / 10\n  Batch    50  of    302.\n  Batch   100  of    302.\n  Batch   150  of    302.\n  Batch   200  of    302.\n  Batch   250  of    302.\n  Batch   300  of    302.\n\nEvaluating...\n  Batch    50  of     65.\n\nTraining Loss: 0.336\nValidation Loss: 0.247\n\n Epoch 9 / 10\n  Batch    50  of    302.\n  Batch   100  of    302.\n  Batch   150  of    302.\n  Batch   200  of    302.\n  Batch   250  of    302.\n  Batch   300  of    302.\n\nEvaluating...\n  Batch    50  of     65.\n\nTraining Loss: 0.317\nValidation Loss: 0.310\n\n Epoch 10 / 10\n  Batch    50  of    302.\n  Batch   100  of    302.\n  Batch   150  of    302.\n  Batch   200  of    302.\n  Batch   250  of    302.\n  Batch   300  of    302.\n\nEvaluating...\n  Batch    50  of     65.\n\nTraining Loss: 0.309\nValidation Loss: 0.216\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"#load weights of best model\npath = 'saved_weights.pt'\nmodel.load_state_dict(torch.load(path))","execution_count":22,"outputs":[{"output_type":"execute_result","execution_count":22,"data":{"text/plain":"<All keys matched successfully>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"# get predictions for test data\nwith torch.no_grad():\n    preds = model(test_seq.to(device), test_mask.to(device))\n    preds = preds.detach().cpu().numpy()","execution_count":23,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# model's performance\npreds = np.argmax(preds, axis = 1)\nprint(classification_report(test_y, preds))","execution_count":24,"outputs":[{"output_type":"stream","text":"              precision    recall  f1-score   support\n\n           0       0.84      0.94      0.89       300\n           1       0.99      0.92      0.96       292\n           2       0.99      0.97      0.98       296\n           3       1.00      0.97      0.98       293\n           4       0.95      0.88      0.91       294\n           5       0.80      0.83      0.81       293\n           6       0.98      1.00      0.99       300\n\n    accuracy                           0.93      2068\n   macro avg       0.94      0.93      0.93      2068\nweighted avg       0.94      0.93      0.93      2068\n\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"# confusion matrix\npd.crosstab(test_y, preds)","execution_count":25,"outputs":[{"output_type":"execute_result","execution_count":25,"data":{"text/plain":"col_0    0    1    2    3    4    5    6\nrow_0                                   \n0      283    1    0    0    0   16    0\n1       18  269    0    0    0    5    0\n2        0    0  288    0    4    3    1\n3        1    0    0  284    0    8    0\n4        1    0    1    0  259   29    4\n5       35    1    1    1   10  244    1\n6        0    0    0    0    0    1  299","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th>col_0</th>\n      <th>0</th>\n      <th>1</th>\n      <th>2</th>\n      <th>3</th>\n      <th>4</th>\n      <th>5</th>\n      <th>6</th>\n    </tr>\n    <tr>\n      <th>row_0</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>283</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>16</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>18</td>\n      <td>269</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>5</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0</td>\n      <td>0</td>\n      <td>288</td>\n      <td>0</td>\n      <td>4</td>\n      <td>3</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>284</td>\n      <td>0</td>\n      <td>8</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>259</td>\n      <td>29</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>35</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>10</td>\n      <td>244</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>299</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"device = torch.device(\"cpu\")\nbert = AutoModel.from_pretrained('bert-base-uncased')\npredict_model = BERT_Arch(bert)\nPATH = 'saved_weights.pt'\npredict_model.load_state_dict(torch.load(PATH,map_location=device))\npredict_model.eval()\ntokenizer = BertTokenizerFast.from_pretrained('bert-base-uncased')","execution_count":31,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def predict(text):\n    \n    tag = {0: 'PlayMusic', 1: 'AddToPlaylist', 2: 'BookRestaurant', 3: 'RateBook', 4: 'SearchScreeningEvent', 5: 'SearchCreativeWork', 6: 'GetWeather'}\n    tokens = tokenizer.tokenize(text)\n    tokens = tokens[:max_seq_len - 2]\n    tokens = ['[CLS]'] + tokens + ['[SEP]']\n\n    input_ids = tokenizer.convert_tokens_to_ids(tokens)\n    input_ids = input_ids + [0] * (max_seq_len-len(input_ids))\n    input_ids = torch.tensor(input_ids).unsqueeze(0)\n    input_ids = input_ids.to(device)\n    \n    input_mask = [1]*len(tokens) + [0] * (max_seq_len - len(tokens))\n    input_mask = torch.tensor(input_mask).unsqueeze(0)\n    input_mask = input_mask.to(device)\n    \n    logits = predict_model(input_ids,input_mask)\n    prob = torch.nn.functional.softmax(logits,dim=1)\n\n    result = [(tag[idx],item *100) for idx,item in enumerate(prob[0].tolist())]\n    preds = logits.detach().cpu().numpy()\n    pred= np.argmax(preds)\n    pred = tag[pred]\n    return result,pred\n    ","execution_count":34,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"list_input = [\"Play music from my relentless playlist\",\n             \"I rate this essay a four of 6\"]\n\nfor item in list_input:\n    confidence,pred = predict(item)\n    print(pred)\n    print(confidence)","execution_count":35,"outputs":[{"output_type":"stream","text":"PlayMusic\n[('PlayMusic', 63.8660192489624), ('AddToPlaylist', 27.898043394088745), ('BookRestaurant', 0.0010027655662270263), ('RateBook', 0.00017184247553814203), ('SearchScreeningEvent', 1.0745170526206493), ('SearchCreativeWork', 7.160063087940216), ('GetWeather', 0.00016551369981243624)]\nRateBook\n[('PlayMusic', 0.00017648445691520465), ('AddToPlaylist', 0.0045816614147042856), ('BookRestaurant', 0.0001809655600482074), ('RateBook', 99.99027252197266), ('SearchScreeningEvent', 0.0006467956154665444), ('SearchCreativeWork', 0.0032689647923689336), ('GetWeather', 0.0008836677807266824)]\n","name":"stdout"}]}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.7.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}