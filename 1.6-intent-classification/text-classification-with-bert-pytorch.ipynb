{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport json\nimport os\nfrom sklearn.metrics import roc_curve\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.metrics import f1_score\nfrom sklearn.model_selection import train_test_split\nimport torch\nimport torch.nn as nn\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import classification_report\nimport transformers\nfrom transformers import BertModel, BertTokenizer\nimport warnings\nwarnings.filterwarnings('ignore')\n# specify GPU\ndevice = torch.device(\"cuda\")\nprint(device)","execution_count":1,"outputs":[{"output_type":"stream","text":"cuda\n","name":"stdout"}]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"class LoadingData():\n            \n    def __init__(self):\n        train_file_path = os.path.join(\"..\",\"input\",\"nlp-benchmarking-data-for-intent-and-entity\",\"benchmarking_data\",\"Train\")\n        validation_file_path = os.path.join(\"..\",\"input\",\"nlp-benchmarking-data-for-intent-and-entity\",\"benchmarking_data\",\"Validate\")\n        category_id = 0\n        self.cat_to_intent = {}\n        self.intent_to_cat = {}\n        \n        for dirname, _, filenames in os.walk(train_file_path):\n            for filename in filenames:\n                file_path = os.path.join(dirname, filename)\n                intent_id = filename.replace(\".json\",\"\")\n                self.cat_to_intent[category_id] = intent_id\n                self.intent_to_cat[intent_id] = category_id\n                category_id+=1\n        print(self.cat_to_intent)\n        print(self.intent_to_cat)\n        '''Training data'''\n        training_data = list() \n        for dirname, _, filenames in os.walk(train_file_path):\n            for filename in filenames:\n                file_path = os.path.join(dirname, filename)\n                intent_id = filename.replace(\".json\",\"\")\n                training_data+=self.make_data_for_intent_from_json(file_path,intent_id,self.intent_to_cat[intent_id])\n        self.train_data_frame = pd.DataFrame(training_data, columns =['query', 'intent','category'])   \n        \n        self.train_data_frame = self.train_data_frame.sample(frac = 1)\n\n\n        \n        '''Validation data'''\n        validation_data = list()    \n        for dirname, _, filenames in os.walk(validation_file_path):\n            for filename in filenames:\n                file_path = os.path.join(dirname, filename)\n                intent_id = filename.replace(\".json\",\"\")\n                validation_data +=self.make_data_for_intent_from_json(file_path,intent_id,self.intent_to_cat[intent_id])                \n        self.validation_data_frame = pd.DataFrame(validation_data, columns =['query', 'intent','category'])\n\n        self.validation_data_frame = self.validation_data_frame.sample(frac = 1)\n        \n        \n    def make_data_for_intent_from_json(self,json_file,intent_id,cat):\n        json_d = json.load(open(json_file))         \n        \n        json_dict = json_d[intent_id]\n\n        sent_list = list()\n        for i in json_dict:\n            each_list = i['data']\n            sent =\"\"\n            for i in each_list:\n                sent = sent + i['text']+ \" \"\n            sent =sent[:-1]\n            for i in range(3):\n                sent = sent.replace(\"  \",\" \")\n            sent_list.append((sent,intent_id,cat))\n        return sent_list","execution_count":2,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ld = LoadingData()","execution_count":3,"outputs":[{"output_type":"stream","text":"{0: 'BookRestaurant', 1: 'SearchScreeningEvent', 2: 'RateBook', 3: 'GetWeather', 4: 'AddToPlaylist', 5: 'PlayMusic', 6: 'SearchCreativeWork'}\n{'BookRestaurant': 0, 'SearchScreeningEvent': 1, 'RateBook': 2, 'GetWeather': 3, 'AddToPlaylist': 4, 'PlayMusic': 5, 'SearchCreativeWork': 6}\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df = ld.train_data_frame","execution_count":4,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"label_map,id2label = ld.intent_to_cat,ld.cat_to_intent","execution_count":5,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_text, val_text, train_labels, val_labels = train_test_split(train_df['query'], train_df['category'], \n                                                                    random_state=2018, \n                                                                    test_size=0.2, \n                                                                    stratify=train_df['category'])","execution_count":6,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Load the BERT tokenizer\ntokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\nbert = BertModel.from_pretrained(\"bert-base-uncased\")","execution_count":7,"outputs":[{"output_type":"display_data","data":{"text/plain":"HBox(children=(FloatProgress(value=0.0, description='Downloading', max=231508.0, style=ProgressStyle(descripti…","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7fe809e219e143b08f6036dfa899cb06"}},"metadata":{}},{"output_type":"stream","text":"\n","name":"stdout"},{"output_type":"display_data","data":{"text/plain":"HBox(children=(FloatProgress(value=0.0, description='Downloading', max=433.0, style=ProgressStyle(description_…","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9f496749d156491cb235422e6a22ab4f"}},"metadata":{}},{"output_type":"stream","text":"\n","name":"stdout"},{"output_type":"display_data","data":{"text/plain":"HBox(children=(FloatProgress(value=0.0, description='Downloading', max=440473133.0, style=ProgressStyle(descri…","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"902730deca3e4324a0c43d7fcbe556fc"}},"metadata":{}},{"output_type":"stream","text":"\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"seq_len = [len(i.split()) for i in train_text]\n\npd.Series(seq_len).hist(bins = 30)\nmax_seq_len = max(seq_len)\nprint(max_seq_len)","execution_count":8,"outputs":[{"output_type":"stream","text":"32\n","name":"stdout"},{"output_type":"display_data","data":{"text/plain":"<Figure size 432x288 with 1 Axes>","image/png":"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\n"},"metadata":{"needs_background":"light"}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"# tokenize and encode sequences in the training set\nif max_seq_len>512:\n    max_seq_len = 512\ntokens_train = tokenizer.batch_encode_plus(\n    train_text.tolist(),\n    max_length = max_seq_len,\n    pad_to_max_length=True,\n    truncation=True,\n    return_token_type_ids=False\n)\n\n# tokenize and encode sequences in the validation set\ntokens_val = tokenizer.batch_encode_plus(\n    val_text.tolist(),\n    max_length = max_seq_len,\n    pad_to_max_length=True,\n    truncation=True,\n    return_token_type_ids=False\n)\n\n","execution_count":9,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# for train set\ntrain_seq = torch.tensor(tokens_train['input_ids'])\ntrain_mask = torch.tensor(tokens_train['attention_mask'])\ntrain_y = torch.tensor(train_labels.tolist())\nprint(\"train_y:\",train_y)\n# for validation set\nval_seq = torch.tensor(tokens_val['input_ids'])\nval_mask = torch.tensor(tokens_val['attention_mask'])\nval_y = torch.tensor(val_labels.tolist())\nprint(\"val_y:\",val_y)\n","execution_count":10,"outputs":[{"output_type":"stream","text":"train_y: tensor([2, 2, 5,  ..., 4, 1, 2])\nval_y: tensor([2, 5, 6,  ..., 6, 3, 2])\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n\n#define a batch size\nbatch_size = 16\n\n# wrap tensors\ntrain_data = TensorDataset(train_seq, train_mask, train_y)\n\n# sampler for sampling the data during training\ntrain_sampler = RandomSampler(train_data)\n\n# dataLoader for train set\ntrain_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n\n# wrap tensors\nval_data = TensorDataset(val_seq, val_mask, val_y)\n\n# sampler for sampling the data during training\nval_sampler = SequentialSampler(val_data)\n\n# dataLoader for validation set\nval_dataloader = DataLoader(val_data, sampler = val_sampler, batch_size=batch_size)","execution_count":11,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# freeze all the parameters\nfor param in bert.parameters():\n    param.requires_grad = False","execution_count":12,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class BERT_Arch(nn.Module):\n    def __init__(self, bert,label_map):\n        super(BERT_Arch, self).__init__()\n        self.bert = bert \n      \n        # dropout layer\n        self.dropout = nn.Dropout(0.1)\n\n        # relu activation function\n        self.relu =  nn.ReLU()\n\n        # dense layer 1\n        self.fc1 = nn.Linear(768,512)\n\n        # dense layer 2 (Output layer)\n        self.fc2 = nn.Linear(512,len(label_map))\n\n        #softmax activation function\n        self.softmax = nn.LogSoftmax(dim=1)\n\n        #define the forward pass\n    def forward(self, sent_id, mask):\n\n        #pass the inputs to the model  \n        _, cls_hs = self.bert(sent_id, attention_mask=mask)\n\n        x = self.fc1(cls_hs)\n\n        x = self.relu(x)\n\n        x = self.dropout(x)\n\n        # output layer\n        x = self.fc2(x)\n\n        # apply softmax activation\n        x = self.softmax(x)\n        return x","execution_count":13,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# pass the pre-trained BERT to our define architecture\nmodel = BERT_Arch(bert,label_map)\n\n# push the model to GPU\nmodel = model.to(device)","execution_count":14,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# optimizer from hugging face transformers\nfrom transformers import AdamW\n\n# define the optimizer\noptimizer = AdamW(model.parameters(), lr = 1e-3)","execution_count":15,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.utils.class_weight import compute_class_weight\n\n#compute the class weights\nclass_wts = compute_class_weight('balanced', np.unique(train_labels), train_labels)\n\nprint(class_wts)","execution_count":16,"outputs":[{"output_type":"stream","text":"[0.99827992 1.00528763 1.00657234 0.98455357 1.01369737 0.98455357\n 1.00786034]\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"# convert class weights to tensor\nweights= torch.tensor(class_wts,dtype=torch.float)\nweights = weights.to(device)\n\n# loss function\ncross_entropy  = nn.NLLLoss(weight=weights) \n\n# number of training epochs\nepochs = 30","execution_count":17,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# function to train the model\ndef train():\n    model.train()\n\n    total_loss, total_accuracy = 0, 0\n  \n    # empty list to save model predictions\n    total_preds=[]\n    total_labels =[]\n  \n    # iterate over batches\n    for step,batch in enumerate(train_dataloader):\n    \n        # progress update after every 50 batches.\n        if step % 100 == 0 and not step == 0:\n            print('  Batch {:>5,}  of  {:>5,}.'.format(step, len(train_dataloader)))\n\n        # push the batch to gpu\n        batch = [r.to(device) for r in batch]\n\n        sent_id, mask, labels = batch\n\n        # clear previously calculated gradients \n        model.zero_grad()        \n\n        # get model predictions for the current batch\n        preds = model(sent_id, mask)\n\n        # compute the loss between actual and predicted values\n        loss = cross_entropy(preds, labels)\n\n        # add on to the total loss\n        total_loss = total_loss + loss.item()\n\n        # backward pass to calculate the gradients\n        loss.backward()\n\n        # clip the the gradients to 1.0. It helps in preventing the exploding gradient problem\n        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n\n        # update parameters\n        optimizer.step()\n\n        # model predictions are stored on GPU. So, push it to CPU\n        preds = preds.detach().cpu().numpy()\n        preds = np.argmax(preds, axis=1)\n        # append the model predictions\n        total_preds+=list(preds)\n        total_labels+=labels.tolist()\n\n    # compute the training loss of the epoch\n    avg_loss = total_loss / len(train_dataloader)\n\n    # predictions are in the form of (no. of batches, size of batch, no. of classes).\n    # reshape the predictions in form of (number of samples, no. of classes)\n    #total_preds  = np.concatenate(total_preds, axis=0)\n    f1 = f1_score(total_labels, total_preds, average='weighted')\n    #returns the loss and predictions\n    return avg_loss, f1","execution_count":27,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# function for evaluating the model\ndef evaluate():\n  \n    print(\"\\nEvaluating...\")\n\n    # deactivate dropout layers\n    model.eval()\n\n    total_loss, total_accuracy = 0, 0\n\n    # empty list to save the model predictions\n    total_preds = []\n    total_labels = []\n    # iterate over batches\n    for step,batch in enumerate(val_dataloader):\n    \n        # Progress update every 50 batches.\n        if step % 50 == 0 and not step == 0:\n\n          # Calculate elapsed time in minutes.\n          #elapsed = format_time(time.time() - t0)\n\n          # Report progress.\n          print('  Batch {:>5,}  of  {:>5,}.'.format(step, len(val_dataloader)))\n\n        # push the batch to gpu\n        batch = [t.to(device) for t in batch]\n\n        sent_id, mask, labels = batch\n\n        # deactivate autograd\n        with torch.no_grad():\n\n            # model predictions\n            preds = model(sent_id, mask)\n\n            # compute the validation loss between actual and predicted values\n            loss = cross_entropy(preds,labels)\n\n            total_loss = total_loss + loss.item()\n\n            preds = preds.detach().cpu().numpy()\n            preds = np.argmax(preds, axis=1)\n            total_preds+=list(preds)\n            total_labels+=labels.tolist()\n    # compute the validation loss of the epoch\n    avg_loss = total_loss / len(val_dataloader) \n\n    # reshape the predictions in form of (number of samples, no. of classes)\n    #total_preds  = np.concatenate(total_preds, axis=0)\n    \n    f1 = f1_score(total_labels, total_preds, average='weighted')\n    return avg_loss, f1","execution_count":28,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def save_checkpoint(filename, epoch, model, optimizer, label_map, id2label):\n    state = {\n        'epoch': epoch,\n        'model': model,\n        'optimizer': optimizer,\n        'label_map': label_map,\n        'id_map':id2label}\n    torch.save(state, filename)","execution_count":20,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# set initial loss to infinite\nbest_valid_loss = float('inf')\n\n# empty lists to store training and validation loss of each epoch\ntrain_losses=[]\nvalid_losses=[]\n\n#for each epoch\nfor epoch in range(epochs):\n     \n    print('\\n Epoch {:} / {:}'.format(epoch + 1, epochs))\n    \n    #train model\n    train_loss, f1_train = train()\n    \n    #evaluate model\n    valid_loss, f1_valid = evaluate()\n    \n    #save the best model\n    if valid_loss < best_valid_loss:\n        best_valid_loss = valid_loss\n        file_name = 'topic_saved_weights.pt'\n        save_checkpoint(file_name, epoch, model, optimizer, label_map, id2label)\n    \n    # append training and validation loss\n    train_losses.append(train_loss)\n    valid_losses.append(valid_loss)\n    \n    print(f'\\nTraining Loss: {train_loss:.3f}')\n    print(f'Validation Loss: {valid_loss:.3f}')\n    print(f'\\nTraining F1: {f1_train:.3f}')\n    print(f'Validation F1: {f1_valid:.3f}')","execution_count":29,"outputs":[{"output_type":"stream","text":"\n Epoch 1 / 30\n  Batch   100  of    690.\n  Batch   200  of    690.\n  Batch   300  of    690.\n  Batch   400  of    690.\n  Batch   500  of    690.\n  Batch   600  of    690.\n\nEvaluating...\n  Batch    50  of    173.\n  Batch   100  of    173.\n  Batch   150  of    173.\n\nTraining Loss: 0.391\nValidation Loss: 0.243\n\nTraining F1: 0.864\nValidation F1: 0.916\n\n Epoch 2 / 30\n  Batch   100  of    690.\n  Batch   200  of    690.\n  Batch   300  of    690.\n  Batch   400  of    690.\n  Batch   500  of    690.\n  Batch   600  of    690.\n\nEvaluating...\n  Batch    50  of    173.\n  Batch   100  of    173.\n  Batch   150  of    173.\n\nTraining Loss: 0.375\nValidation Loss: 0.375\n\nTraining F1: 0.865\nValidation F1: 0.857\n\n Epoch 3 / 30\n  Batch   100  of    690.\n  Batch   200  of    690.\n  Batch   300  of    690.\n  Batch   400  of    690.\n  Batch   500  of    690.\n  Batch   600  of    690.\n\nEvaluating...\n  Batch    50  of    173.\n  Batch   100  of    173.\n  Batch   150  of    173.\n\nTraining Loss: 0.360\nValidation Loss: 0.223\n\nTraining F1: 0.872\nValidation F1: 0.925\n\n Epoch 4 / 30\n  Batch   100  of    690.\n  Batch   200  of    690.\n  Batch   300  of    690.\n  Batch   400  of    690.\n  Batch   500  of    690.\n  Batch   600  of    690.\n\nEvaluating...\n  Batch    50  of    173.\n  Batch   100  of    173.\n  Batch   150  of    173.\n\nTraining Loss: 0.340\nValidation Loss: 0.196\n\nTraining F1: 0.881\nValidation F1: 0.931\n\n Epoch 5 / 30\n  Batch   100  of    690.\n  Batch   200  of    690.\n  Batch   300  of    690.\n  Batch   400  of    690.\n  Batch   500  of    690.\n  Batch   600  of    690.\n\nEvaluating...\n  Batch    50  of    173.\n  Batch   100  of    173.\n  Batch   150  of    173.\n\nTraining Loss: 0.328\nValidation Loss: 0.207\n\nTraining F1: 0.888\nValidation F1: 0.926\n\n Epoch 6 / 30\n  Batch   100  of    690.\n  Batch   200  of    690.\n  Batch   300  of    690.\n  Batch   400  of    690.\n  Batch   500  of    690.\n  Batch   600  of    690.\n\nEvaluating...\n  Batch    50  of    173.\n  Batch   100  of    173.\n  Batch   150  of    173.\n\nTraining Loss: 0.341\nValidation Loss: 0.310\n\nTraining F1: 0.882\nValidation F1: 0.889\n\n Epoch 7 / 30\n  Batch   100  of    690.\n  Batch   200  of    690.\n  Batch   300  of    690.\n  Batch   400  of    690.\n  Batch   500  of    690.\n  Batch   600  of    690.\n\nEvaluating...\n  Batch    50  of    173.\n  Batch   100  of    173.\n  Batch   150  of    173.\n\nTraining Loss: 0.308\nValidation Loss: 0.197\n\nTraining F1: 0.894\nValidation F1: 0.932\n\n Epoch 8 / 30\n  Batch   100  of    690.\n  Batch   200  of    690.\n  Batch   300  of    690.\n  Batch   400  of    690.\n  Batch   500  of    690.\n  Batch   600  of    690.\n\nEvaluating...\n  Batch    50  of    173.\n  Batch   100  of    173.\n  Batch   150  of    173.\n\nTraining Loss: 0.309\nValidation Loss: 0.280\n\nTraining F1: 0.891\nValidation F1: 0.911\n\n Epoch 9 / 30\n  Batch   100  of    690.\n  Batch   200  of    690.\n  Batch   300  of    690.\n  Batch   400  of    690.\n  Batch   500  of    690.\n  Batch   600  of    690.\n\nEvaluating...\n  Batch    50  of    173.\n  Batch   100  of    173.\n  Batch   150  of    173.\n\nTraining Loss: 0.306\nValidation Loss: 0.211\n\nTraining F1: 0.896\nValidation F1: 0.919\n\n Epoch 10 / 30\n  Batch   100  of    690.\n  Batch   200  of    690.\n  Batch   300  of    690.\n  Batch   400  of    690.\n  Batch   500  of    690.\n  Batch   600  of    690.\n\nEvaluating...\n  Batch    50  of    173.\n  Batch   100  of    173.\n  Batch   150  of    173.\n\nTraining Loss: 0.294\nValidation Loss: 0.201\n\nTraining F1: 0.896\nValidation F1: 0.929\n\n Epoch 11 / 30\n  Batch   100  of    690.\n  Batch   200  of    690.\n  Batch   300  of    690.\n  Batch   400  of    690.\n  Batch   500  of    690.\n  Batch   600  of    690.\n\nEvaluating...\n  Batch    50  of    173.\n  Batch   100  of    173.\n  Batch   150  of    173.\n\nTraining Loss: 0.294\nValidation Loss: 0.170\n\nTraining F1: 0.897\nValidation F1: 0.942\n\n Epoch 12 / 30\n  Batch   100  of    690.\n  Batch   200  of    690.\n  Batch   300  of    690.\n  Batch   400  of    690.\n  Batch   500  of    690.\n  Batch   600  of    690.\n\nEvaluating...\n  Batch    50  of    173.\n  Batch   100  of    173.\n  Batch   150  of    173.\n\nTraining Loss: 0.296\nValidation Loss: 0.207\n\nTraining F1: 0.898\nValidation F1: 0.927\n\n Epoch 13 / 30\n  Batch   100  of    690.\n  Batch   200  of    690.\n  Batch   300  of    690.\n  Batch   400  of    690.\n  Batch   500  of    690.\n  Batch   600  of    690.\n\nEvaluating...\n  Batch    50  of    173.\n  Batch   100  of    173.\n  Batch   150  of    173.\n\nTraining Loss: 0.283\nValidation Loss: 0.303\n\nTraining F1: 0.901\nValidation F1: 0.893\n\n Epoch 14 / 30\n  Batch   100  of    690.\n  Batch   200  of    690.\n  Batch   300  of    690.\n  Batch   400  of    690.\n  Batch   500  of    690.\n  Batch   600  of    690.\n\nEvaluating...\n  Batch    50  of    173.\n  Batch   100  of    173.\n  Batch   150  of    173.\n\nTraining Loss: 0.289\nValidation Loss: 0.228\n\nTraining F1: 0.899\nValidation F1: 0.922\n\n Epoch 15 / 30\n  Batch   100  of    690.\n  Batch   200  of    690.\n  Batch   300  of    690.\n  Batch   400  of    690.\n  Batch   500  of    690.\n  Batch   600  of    690.\n\nEvaluating...\n  Batch    50  of    173.\n  Batch   100  of    173.\n  Batch   150  of    173.\n\nTraining Loss: 0.281\nValidation Loss: 0.164\n\nTraining F1: 0.902\nValidation F1: 0.943\n\n Epoch 16 / 30\n  Batch   100  of    690.\n  Batch   200  of    690.\n  Batch   300  of    690.\n  Batch   400  of    690.\n  Batch   500  of    690.\n  Batch   600  of    690.\n\nEvaluating...\n  Batch    50  of    173.\n  Batch   100  of    173.\n  Batch   150  of    173.\n\nTraining Loss: 0.269\nValidation Loss: 0.206\n\nTraining F1: 0.907\nValidation F1: 0.931\n\n Epoch 17 / 30\n  Batch   100  of    690.\n  Batch   200  of    690.\n  Batch   300  of    690.\n  Batch   400  of    690.\n  Batch   500  of    690.\n  Batch   600  of    690.\n\nEvaluating...\n  Batch    50  of    173.\n  Batch   100  of    173.\n  Batch   150  of    173.\n\nTraining Loss: 0.283\nValidation Loss: 0.213\n\nTraining F1: 0.903\nValidation F1: 0.926\n\n Epoch 18 / 30\n  Batch   100  of    690.\n  Batch   200  of    690.\n  Batch   300  of    690.\n  Batch   400  of    690.\n  Batch   500  of    690.\n  Batch   600  of    690.\n\nEvaluating...\n  Batch    50  of    173.\n  Batch   100  of    173.\n  Batch   150  of    173.\n\nTraining Loss: 0.267\nValidation Loss: 0.195\n\nTraining F1: 0.909\nValidation F1: 0.931\n\n Epoch 19 / 30\n  Batch   100  of    690.\n  Batch   200  of    690.\n  Batch   300  of    690.\n  Batch   400  of    690.\n  Batch   500  of    690.\n  Batch   600  of    690.\n\nEvaluating...\n  Batch    50  of    173.\n  Batch   100  of    173.\n  Batch   150  of    173.\n\nTraining Loss: 0.261\nValidation Loss: 0.150\n\nTraining F1: 0.909\nValidation F1: 0.951\n\n Epoch 20 / 30\n  Batch   100  of    690.\n  Batch   200  of    690.\n  Batch   300  of    690.\n  Batch   400  of    690.\n  Batch   500  of    690.\n  Batch   600  of    690.\n\nEvaluating...\n  Batch    50  of    173.\n  Batch   100  of    173.\n  Batch   150  of    173.\n\nTraining Loss: 0.252\nValidation Loss: 0.206\n\nTraining F1: 0.914\nValidation F1: 0.933\n\n Epoch 21 / 30\n  Batch   100  of    690.\n  Batch   200  of    690.\n  Batch   300  of    690.\n  Batch   400  of    690.\n  Batch   500  of    690.\n  Batch   600  of    690.\n\nEvaluating...\n  Batch    50  of    173.\n  Batch   100  of    173.\n  Batch   150  of    173.\n\nTraining Loss: 0.266\nValidation Loss: 0.164\n\nTraining F1: 0.909\nValidation F1: 0.948\n\n Epoch 22 / 30\n  Batch   100  of    690.\n  Batch   200  of    690.\n  Batch   300  of    690.\n  Batch   400  of    690.\n  Batch   500  of    690.\n  Batch   600  of    690.\n\nEvaluating...\n  Batch    50  of    173.\n  Batch   100  of    173.\n  Batch   150  of    173.\n\nTraining Loss: 0.267\nValidation Loss: 0.153\n\nTraining F1: 0.909\nValidation F1: 0.945\n\n Epoch 23 / 30\n  Batch   100  of    690.\n  Batch   200  of    690.\n  Batch   300  of    690.\n  Batch   400  of    690.\n  Batch   500  of    690.\n  Batch   600  of    690.\n\nEvaluating...\n  Batch    50  of    173.\n  Batch   100  of    173.\n  Batch   150  of    173.\n\nTraining Loss: 0.246\nValidation Loss: 0.180\n\nTraining F1: 0.916\nValidation F1: 0.941\n\n Epoch 24 / 30\n  Batch   100  of    690.\n  Batch   200  of    690.\n  Batch   300  of    690.\n  Batch   400  of    690.\n  Batch   500  of    690.\n","name":"stdout"},{"output_type":"stream","text":"  Batch   600  of    690.\n\nEvaluating...\n  Batch    50  of    173.\n  Batch   100  of    173.\n  Batch   150  of    173.\n\nTraining Loss: 0.261\nValidation Loss: 0.146\n\nTraining F1: 0.910\nValidation F1: 0.952\n\n Epoch 25 / 30\n  Batch   100  of    690.\n  Batch   200  of    690.\n  Batch   300  of    690.\n  Batch   400  of    690.\n  Batch   500  of    690.\n  Batch   600  of    690.\n\nEvaluating...\n  Batch    50  of    173.\n  Batch   100  of    173.\n  Batch   150  of    173.\n\nTraining Loss: 0.260\nValidation Loss: 0.152\n\nTraining F1: 0.908\nValidation F1: 0.948\n\n Epoch 26 / 30\n  Batch   100  of    690.\n  Batch   200  of    690.\n  Batch   300  of    690.\n  Batch   400  of    690.\n  Batch   500  of    690.\n  Batch   600  of    690.\n\nEvaluating...\n  Batch    50  of    173.\n  Batch   100  of    173.\n  Batch   150  of    173.\n\nTraining Loss: 0.257\nValidation Loss: 0.178\n\nTraining F1: 0.908\nValidation F1: 0.939\n\n Epoch 27 / 30\n  Batch   100  of    690.\n  Batch   200  of    690.\n  Batch   300  of    690.\n  Batch   400  of    690.\n  Batch   500  of    690.\n  Batch   600  of    690.\n\nEvaluating...\n  Batch    50  of    173.\n  Batch   100  of    173.\n  Batch   150  of    173.\n\nTraining Loss: 0.245\nValidation Loss: 0.151\n\nTraining F1: 0.914\nValidation F1: 0.952\n\n Epoch 28 / 30\n  Batch   100  of    690.\n  Batch   200  of    690.\n  Batch   300  of    690.\n  Batch   400  of    690.\n  Batch   500  of    690.\n  Batch   600  of    690.\n\nEvaluating...\n  Batch    50  of    173.\n  Batch   100  of    173.\n  Batch   150  of    173.\n\nTraining Loss: 0.246\nValidation Loss: 0.146\n\nTraining F1: 0.915\nValidation F1: 0.952\n\n Epoch 29 / 30\n  Batch   100  of    690.\n  Batch   200  of    690.\n  Batch   300  of    690.\n  Batch   400  of    690.\n  Batch   500  of    690.\n  Batch   600  of    690.\n\nEvaluating...\n  Batch    50  of    173.\n  Batch   100  of    173.\n  Batch   150  of    173.\n\nTraining Loss: 0.240\nValidation Loss: 0.157\n\nTraining F1: 0.917\nValidation F1: 0.949\n\n Epoch 30 / 30\n  Batch   100  of    690.\n  Batch   200  of    690.\n  Batch   300  of    690.\n  Batch   400  of    690.\n  Batch   500  of    690.\n  Batch   600  of    690.\n\nEvaluating...\n  Batch    50  of    173.\n  Batch   100  of    173.\n  Batch   150  of    173.\n\nTraining Loss: 0.242\nValidation Loss: 0.162\n\nTraining F1: 0.918\nValidation F1: 0.946\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"path = 'topic_saved_weights.pt'\ntest_df = ld.validation_data_frame\n\ncheckpoint = torch.load(path,map_location=device)\nmodel = checkpoint.get(\"model\")\ntokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n\n\n# tokenize and encode sequences in the test set\ntest_text,test_labels = test_df[\"query\"],test_df[\"category\"]\n\ntokens_test = tokenizer.batch_encode_plus(\n    test_text.tolist(),\n    max_length = max_seq_len,\n    pad_to_max_length=True,\n    truncation=True,\n    return_token_type_ids=False\n)\n\n# for test set\ntest_seq = torch.tensor(tokens_test['input_ids'])\ntest_mask = torch.tensor(tokens_test['attention_mask'])\ntest_y = torch.tensor(test_labels.tolist())\nprint(\"test_y:\",test_y)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# get predictions for test data\nwith torch.no_grad():\n    preds = model(test_seq.to(device), test_mask.to(device))\n    preds = preds.detach().cpu().numpy()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"preds = np.argmax(preds, axis = 1)\nprint(classification_report(test_y, preds))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class Prediction:\n    def __init__(self):\n        path = 'topic_saved_weights.pt'\n\n        checkpoint = torch.load(path,map_location=device)\n        self.predictor = checkpoint.get(\"model\")\n        self.tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n        self.tag = checkpoint.get(\"id_map\")\n\n    def predict(self,text):\n        tokens = self.tokenizer.tokenize(text)\n        tokens = tokens[:max_seq_len - 2]\n        tokens = ['[CLS]'] + tokens + ['[SEP]']\n\n        input_ids = self.tokenizer.convert_tokens_to_ids(tokens)\n        input_ids = input_ids + [0] * (max_seq_len-len(input_ids))\n        input_ids = torch.tensor(input_ids).unsqueeze(0)\n        input_ids = input_ids.to(device)\n\n        input_mask = [1]*len(tokens) + [0] * (max_seq_len - len(tokens))\n        input_mask = torch.tensor(input_mask).unsqueeze(0)\n        input_mask = input_mask.to(device)\n\n        logits = self.predictor(input_ids,input_mask)\n        prob = torch.nn.functional.softmax(logits,dim=1)\n        result = [(self.tag[idx],item *100) for idx,item in enumerate(prob[0].tolist())]\n        preds = logits.detach().cpu().numpy()\n        pred_val = np.argmax(preds)\n        pred_val = self.tag[pred_val]\n        return result,pred_val\n","execution_count":45,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pred = Prediction()","execution_count":46,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"list_input = [\"Play music from my relentless playlist\",\n             \"I rate this essay a four of 6\"]\n\nfor item in list_input:\n    confidence,pred_val = pred.predict(item)\n    print(pred_val)\n    print(confidence)","execution_count":47,"outputs":[{"output_type":"stream","text":"PlayMusic\n[('BookRestaurant', 1.2048614905779687e-05), ('SearchScreeningEvent', 0.06772816996090114), ('RateBook', 7.69690757351782e-05), ('GetWeather', 7.716318251027587e-07), ('AddToPlaylist', 41.87126159667969), ('PlayMusic', 56.4595103263855), ('SearchCreativeWork', 1.6014140099287033)]\nRateBook\n[('BookRestaurant', 1.0315424070483914e-06), ('SearchScreeningEvent', 2.932396769850243e-07), ('RateBook', 100.0), ('GetWeather', 8.08519862172119e-08), ('AddToPlaylist', 3.296656814200105e-06), ('PlayMusic', 1.5063672531567818e-08), ('SearchCreativeWork', 1.3556576305973067e-06)]\n","name":"stdout"}]}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.7.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}